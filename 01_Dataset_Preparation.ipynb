{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "01_Dataset_Preparation.ipynb"
      ],
      "metadata": {
        "id": "8zadUGr9LCi5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(A) 분야 및 데이터 출처 :\n",
        "\n",
        "본 프로젝트는 컴퓨터 비전 분야에 해당하며, 특정 객체(칼)를 분류하는 이미지 분류 문제입니다.\n",
        "주제와 데이터 모두 본인이 직접 생성하였으며, 영상 19개를 촬영한 후 이미지로 분할·가공하여 학습용 데이터를 구성하였습니다.\n",
        "\n",
        "(B) 모델 목적:\n",
        "\n",
        "다양한 실제 환경(조도, 배경, 오클루전, 칼 종류)에 따라 칼의 인식 정확도가 어떻게 달라지는지 비교하기 위해,\n",
        "4가지 CNN 모델(VGG16, ResNet50, DenseNet121, EfficientNetB0)의 성능을 조건별로 분석하고\n",
        "현실에서 강건한(robust) 칼 분류 모델을 탐색하는 것이 목적입니다.\n",
        "\n",
        "(C) 데이터 종류 및 양 :\n",
        "\n",
        "\n",
        "- 데이터 종류: 이미지 (RGB, 224x224)\n",
        "\n",
        "- 데이터 출처: 본인이 직접 촬영한 영상 19편에서 프레임을 추출하여 가공\n",
        "\n",
        "- 총 이미지 수: 약 15,800장\n",
        "\n",
        "- 구성: 조도(bright/dark), 배경(5종), 오클루전 유무, 칼 종류(3종) 등 다양한 조건 조합으로 구성된 커스텀 데이터셋\n",
        "\n",
        "(D) 입력 데이터 및 방식 :\n",
        "\n",
        "각 모델에는 224x224 크기의 RGB 칼 이미지가 입력됩니다.\n",
        "이미지는 전처리 과정을 거쳐 모델에 주어지며, 모델은 이를 기반으로 칼의 존재 여부 및 종류를 분류합니다.\n",
        "\n",
        "(E) 출력 결과 및 의미\n",
        "\n",
        "모델의 출력은 **분류 결과(label)**로, ‘커터칼’, ‘과도’, ‘식칼’, ‘칼 없음’ 중 하나를 예측합니다.\n",
        "\n",
        "이를 기반으로 조건별 정확도를 분석하여, 환경 변화에 강한 최적의 모델을 도출하는 것이 실험의 핵심입니다."
      ],
      "metadata": {
        "id": "mozrZ04Skq-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 01_Dataset_Preparation"
      ],
      "metadata": {
        "id": "CrbqS8ENgBqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (1) 주제\n",
        "\n",
        "칼 이미지에 대한 다양한 조건(조도, 배경, 칼 종류, 오클루전)을 반영한 이미지 분류 실험\n",
        "\n",
        "---\n",
        "\n",
        "## (2) Motivation\n",
        "\n",
        "실생활에서 위험 물체(칼)를 다양한 환경에서 인식하는 것은 영상 처리 시스템의 중요한 문제 중 하나이다.\n",
        "\n",
        "본 프로젝트에서는 YOLOv8을 활용해 직접 촬영한 영상에서 칼 이미지를 추출하고,\n",
        "\n",
        "여러 CNN 기반 분류 모델(VGG16, ResNet50, DenseNet121, EfficientNetB0)을 비교하여,\n",
        "\n",
        "환경 조건별로 어떤 모델이 효과적인지를 분석하고자 한다.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## (3) 사용하는 기존 (인터넷 상) 데이터 수급 방법에 대한 설명\n",
        "\n",
        "본 프로젝트는 외부에서 수집한 공개 데이터셋을 사용하지 않았으며,  \n",
        "모든 데이터는 본인이 직접 촬영한 영상으로부터 YOLOv8 모델을 활용하여 칼 이미지를 추출해 구성하였다.\n",
        "\n",
        "[Note 1]\n",
        "\n",
        "본 과제에서는 전이학습 기반 모델을 사용하였으며, 아래의 사전 학습(pre-trained) 모델들을 활용하였다.\n",
        "\n",
        "- VGG16\n",
        "- ResNet50\n",
        "- DenseNet121\n",
        "- EfficientNetB0\n",
        "\n",
        "이들 모델은 Keras의 `keras.applications` 모듈을 통해 제공되며,  \n",
        "`ImageNet` 데이터셋으로 사전 학습된 가중치를 불러와 출력층을 수정하여 분류 학습에 사용하였다.\n",
        "\n",
        "외부에서 추가적으로 가져온 데이터는 없으며, 학습에는 본인이 직접 생성한 이미지 데이터만을 활용하였다.\n",
        "\n",
        "[Note 2]\n",
        "\n",
        "본 프로젝트는 본인이 직접 촬영한 19개의 영상(식칼, 과도, 커터칼 × 다양한 조건)을 기반으로 하고 있으며,  \n",
        "이 영상들은 수업 과제 제출을 목적으로 촬영되었기 때문에 별도의 외부 공유 링크는 존재하지 않는다."
      ],
      "metadata": {
        "id": "WidTvIx7ad-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Drive 마운트\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcAy-jkULyVT",
        "outputId": "942851c2-924d-48c4-d07f-dc8b211033b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "2w3joMeJYont"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 라이브러리 설치\n",
        "\n",
        "!pip install ultralytics opencv-python --quiet"
      ],
      "metadata": {
        "id": "bWpyCC49MGZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. YOLOv8 모델 로드 및 탐지 함수 정의\n",
        "\n",
        "from ultralytics import YOLO\n",
        "model = YOLO('yolov8s.pt')  # 실험용 데이터셋 생성에 최적"
      ],
      "metadata": {
        "id": "zCLIXOlMMmRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c349e95-9cd6-40a4-fc47-9c718e54a3fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21.5M/21.5M [00:00<00:00, 150MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "qVup0CdzYlf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 영상 경로 설정\n",
        "\n",
        "video_base_path = \"/content/drive/MyDrive/knife_videos\""
      ],
      "metadata": {
        "id": "6rPG_5ahNFEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 탐지 함수 정의\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def extract_knives_from_video(video_path, save_dir, conf=0.25, save_limit=50):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = 0\n",
        "    saved = 0\n",
        "\n",
        "    while cap.isOpened() and saved < save_limit:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        results = model(frame)\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                cls = int(box.cls[0])\n",
        "                label = model.names[cls]\n",
        "\n",
        "                if label == 'knife':\n",
        "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                    crop = frame[y1:y2, x1:x2]\n",
        "                    filename = f\"{save_dir}/knife_{frame_count:04d}.jpg\"\n",
        "                    cv2.imwrite(filename, crop)\n",
        "                    saved += 1\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"[{os.path.basename(video_path)}] 저장 완료: {saved}장\")"
      ],
      "metadata": {
        "id": "Bpo0GlDtORzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 영상 리스트 반복 처리\n",
        "\n",
        "video_files = [\n",
        "    \"knife01_bright_kitchen_식칼_none.mp4\",\n",
        "    \"knife02_dark_desk_과도_none.mp4\",\n",
        "    \"knife03_bright_livingroom_커터칼_yes.mp4\",\n",
        "    \"knife04_bright_floor_식칼_none.mp4\",\n",
        "    \"knife05_dark_kitchen_과도_yes.mp4\",\n",
        "    \"knife06_bright_window_커터칼_none.mp4\",\n",
        "    \"knife07_bright_desk_식칼_yes.mp4\",\n",
        "    \"knife08_dark_livingroom_커터칼_none.mp4\",\n",
        "    \"knife09_dark_floor_커터칼_yes.mp4\",\n",
        "    \"knife10_dark_window_커터칼_yes.mp4\",\n",
        "    \"knife11_bright_floor_커터칼_yes.mp4\",\n",
        "    \"knife12_dark_kitchen_커터칼_none.mp4\",\n",
        "    \"knife13_bright_window_커터칼_yes.mp4\",\n",
        "    \"knife14_dark_floor_과도_yes.mp4\",\n",
        "    \"knife15_bright_kitchen_과도_none.mp4\",\n",
        "    \"knife16_bright_floor_과도_yes.mp4\",\n",
        "    \"knife17_bright_desk_식칼_yes.mp4\",\n",
        "    \"knife18_bright_window_커터칼_yes.mp4\",\n",
        "    \"knife19_dark_livingroom_식칼_none.mp4\"\n",
        "]\n",
        "\n",
        "for file in video_files:\n",
        "    video_path = os.path.join(video_base_path, file)\n",
        "    save_dir = f\"/content/knives_dataset/{file.replace('.mp4','')}\"\n",
        "    extract_knives_from_video(video_path, save_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ4HuteROfIr",
        "outputId": "0276b1a4-3858-4c23-ba2b-69507147f85e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 9.5ms\n",
            "Speed: 1.7ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 1 scissors, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 1 toothbrush, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 1 toothbrush, 9.9ms\n",
            "Speed: 4.0ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 10.1ms\n",
            "Speed: 5.3ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 1 toothbrush, 12.4ms\n",
            "Speed: 4.8ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 10.2ms\n",
            "Speed: 3.0ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 8.6ms\n",
            "Speed: 7.9ms preprocess, 8.6ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 9.3ms\n",
            "Speed: 3.6ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 1 cell phone, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 1 cell phone, 8.3ms\n",
            "Speed: 2.5ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 9.3ms\n",
            "Speed: 2.5ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 1 cell phone, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 1 scissors, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.6ms\n",
            "Speed: 2.1ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.9ms\n",
            "Speed: 2.2ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.1ms\n",
            "Speed: 2.4ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.4ms\n",
            "Speed: 2.2ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.9ms\n",
            "Speed: 2.2ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.9ms\n",
            "Speed: 2.2ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 10.6ms\n",
            "Speed: 2.5ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.5ms\n",
            "Speed: 2.7ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.2ms\n",
            "Speed: 3.4ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 10.9ms\n",
            "Speed: 2.2ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 10.8ms\n",
            "Speed: 2.4ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.9ms\n",
            "Speed: 2.4ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 1 scissors, 9.0ms\n",
            "Speed: 2.4ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 cell phone, 8.9ms\n",
            "Speed: 2.2ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 cell phone, 1 scissors, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.2ms\n",
            "Speed: 2.4ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.4ms\n",
            "Speed: 2.9ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.9ms\n",
            "Speed: 2.2ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.2ms\n",
            "Speed: 3.0ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.0ms\n",
            "Speed: 2.3ms preprocess, 11.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 toothbrush, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 cell phone, 1 scissors, 10.8ms\n",
            "Speed: 2.3ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.5ms\n",
            "Speed: 2.3ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 8.9ms\n",
            "Speed: 2.8ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 15.0ms\n",
            "Speed: 5.1ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 12.2ms\n",
            "Speed: 2.5ms preprocess, 12.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.8ms\n",
            "Speed: 2.8ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.7ms\n",
            "Speed: 2.5ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.1ms\n",
            "Speed: 2.6ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.1ms\n",
            "Speed: 3.6ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.9ms\n",
            "Speed: 2.7ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.7ms\n",
            "Speed: 2.8ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.0ms\n",
            "Speed: 3.3ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.5ms\n",
            "Speed: 4.0ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.6ms\n",
            "Speed: 2.5ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.1ms\n",
            "Speed: 2.4ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 1.7ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.4ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 4.6ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 3.1ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.4ms\n",
            "Speed: 3.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.3ms\n",
            "Speed: 2.8ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.6ms\n",
            "Speed: 3.4ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.6ms\n",
            "Speed: 3.7ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.6ms\n",
            "Speed: 3.7ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.5ms\n",
            "Speed: 3.4ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.1ms\n",
            "Speed: 3.3ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 2.2ms preprocess, 10.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 1 scissors, 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 1 scissors, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 1 scissors, 10.1ms\n",
            "Speed: 2.4ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 1 scissors, 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 1 scissors, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 1 scissors, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 1 scissors, 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 1 scissors, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 1 scissors, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 15.7ms\n",
            "Speed: 2.2ms preprocess, 15.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 10.7ms\n",
            "Speed: 3.0ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 12.4ms\n",
            "Speed: 2.3ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.3ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.6ms\n",
            "Speed: 4.6ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 3.2ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.2ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 2.2ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 2.7ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.9ms\n",
            "Speed: 3.1ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 2.3ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 2.4ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball bat, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 baseball bats, 13.1ms\n",
            "Speed: 2.1ms preprocess, 13.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 9.7ms\n",
            "Speed: 2.2ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 8.6ms\n",
            "Speed: 2.1ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "[knife13_bright_window_커터칼_yes.mp4] 저장 완료: 50장\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 knife, 14.0ms\n",
            "Speed: 2.8ms preprocess, 14.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 20.0ms\n",
            "Speed: 6.5ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 knife, 15.0ms\n",
            "Speed: 2.2ms preprocess, 15.0ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 15.3ms\n",
            "Speed: 2.5ms preprocess, 15.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 knife, 11.3ms\n",
            "Speed: 4.0ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 14.1ms\n",
            "Speed: 2.3ms preprocess, 14.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 13.6ms\n",
            "Speed: 2.9ms preprocess, 13.6ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 11.2ms\n",
            "Speed: 2.4ms preprocess, 11.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 14.4ms\n",
            "Speed: 2.3ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 knife, 14.1ms\n",
            "Speed: 2.0ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 19.8ms\n",
            "Speed: 2.1ms preprocess, 19.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 13.3ms\n",
            "Speed: 2.2ms preprocess, 13.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 18.2ms\n",
            "Speed: 2.1ms preprocess, 18.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 16.8ms\n",
            "Speed: 2.2ms preprocess, 16.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 12.7ms\n",
            "Speed: 2.1ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 13.3ms\n",
            "Speed: 2.1ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 14.2ms\n",
            "Speed: 2.0ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 10.7ms\n",
            "Speed: 2.7ms preprocess, 10.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 11.2ms\n",
            "Speed: 3.7ms preprocess, 11.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 11.9ms\n",
            "Speed: 2.3ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 16.6ms\n",
            "Speed: 2.1ms preprocess, 16.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 15.1ms\n",
            "Speed: 2.5ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 15.7ms\n",
            "Speed: 2.1ms preprocess, 15.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 13.7ms\n",
            "Speed: 2.3ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 14.4ms\n",
            "Speed: 2.2ms preprocess, 14.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "[knife14_dark_floor_과도_yes.mp4] 저장 완료: 50장\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 25.5ms\n",
            "Speed: 2.5ms preprocess, 25.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 23.5ms\n",
            "Speed: 2.1ms preprocess, 23.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 13.7ms\n",
            "Speed: 2.1ms preprocess, 13.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 19.0ms\n",
            "Speed: 2.2ms preprocess, 19.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.2ms\n",
            "Speed: 2.3ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.3ms\n",
            "Speed: 2.4ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.9ms\n",
            "Speed: 2.3ms preprocess, 13.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.3ms\n",
            "Speed: 2.0ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.5ms\n",
            "Speed: 2.8ms preprocess, 12.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 17.7ms\n",
            "Speed: 2.2ms preprocess, 17.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.4ms\n",
            "Speed: 3.6ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 18.0ms\n",
            "Speed: 2.1ms preprocess, 18.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.9ms\n",
            "Speed: 2.0ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 15.8ms\n",
            "Speed: 2.0ms preprocess, 15.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 17.5ms\n",
            "Speed: 3.6ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.7ms\n",
            "Speed: 2.2ms preprocess, 12.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.7ms\n",
            "Speed: 3.6ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.8ms\n",
            "Speed: 2.8ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.8ms\n",
            "Speed: 3.1ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.0ms\n",
            "Speed: 3.5ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.6ms\n",
            "Speed: 2.4ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 14.5ms\n",
            "Speed: 2.2ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 14.4ms\n",
            "Speed: 2.0ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.8ms\n",
            "Speed: 2.1ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.5ms\n",
            "Speed: 2.5ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.7ms\n",
            "Speed: 2.4ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.0ms\n",
            "Speed: 2.4ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.8ms\n",
            "Speed: 4.1ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 13.4ms\n",
            "Speed: 3.2ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.5ms\n",
            "Speed: 2.2ms preprocess, 14.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 10.1ms\n",
            "Speed: 2.3ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 mouse, 8.9ms\n",
            "Speed: 2.4ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 mouse, 1 scissors, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 8.4ms\n",
            "Speed: 2.5ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 2 scissorss, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 mouse, 2 scissorss, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 mouse, 2 scissorss, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 2 scissorss, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 2 scissorss, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 8.6ms\n",
            "Speed: 2.1ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 mouse, 1 scissors, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 mouse, 14.1ms\n",
            "Speed: 2.3ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 13.8ms\n",
            "Speed: 2.1ms preprocess, 13.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 11.1ms\n",
            "Speed: 3.3ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 13.8ms\n",
            "Speed: 2.2ms preprocess, 13.8ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 20.0ms\n",
            "Speed: 2.2ms preprocess, 20.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 13.5ms\n",
            "Speed: 2.1ms preprocess, 13.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 2 scissorss, 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 13.4ms\n",
            "Speed: 2.3ms preprocess, 13.4ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 11.5ms\n",
            "Speed: 2.2ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 17.3ms\n",
            "Speed: 2.9ms preprocess, 17.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 17.6ms\n",
            "Speed: 2.1ms preprocess, 17.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 20.2ms\n",
            "Speed: 2.0ms preprocess, 20.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 16.0ms\n",
            "Speed: 2.1ms preprocess, 16.0ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 20.0ms\n",
            "Speed: 2.1ms preprocess, 20.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toilet, 1 scissors, 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toilet, 1 scissors, 9.9ms\n",
            "Speed: 2.2ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toilet, 1 scissors, 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.3ms\n",
            "Speed: 6.2ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 mouse, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 mouse, 1 scissors, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 mouse, 1 scissors, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 mouse, 1 scissors, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 mouse, 10.3ms\n",
            "Speed: 2.6ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 mouse, 13.3ms\n",
            "Speed: 2.1ms preprocess, 13.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 mouse, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 mouse, 1 scissors, 10.3ms\n",
            "Speed: 3.0ms preprocess, 10.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 mouse, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 mouse, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 mouse, 15.0ms\n",
            "Speed: 2.0ms preprocess, 15.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bowl, 1 mouse, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bowl, 1 mouse, 13.8ms\n",
            "Speed: 2.7ms preprocess, 13.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bowl, 1 mouse, 1 scissors, 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bowl, 1 mouse, 11.8ms\n",
            "Speed: 2.5ms preprocess, 11.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bowl, 1 mouse, 1 scissors, 11.7ms\n",
            "Speed: 3.8ms preprocess, 11.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bowl, 1 scissors, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bowl, 1 mouse, 2 scissorss, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.0ms\n",
            "Speed: 2.5ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.3ms\n",
            "Speed: 2.9ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toilet, 1 scissors, 11.0ms\n",
            "Speed: 2.3ms preprocess, 11.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toilet, 1 scissors, 14.2ms\n",
            "Speed: 2.6ms preprocess, 14.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toilet, 1 scissors, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 15.5ms\n",
            "Speed: 2.1ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.3ms\n",
            "Speed: 3.4ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 15.1ms\n",
            "Speed: 2.1ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.4ms\n",
            "Speed: 4.4ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.2ms\n",
            "Speed: 2.2ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.3ms\n",
            "Speed: 5.4ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bowl, 1 scissors, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.4ms\n",
            "Speed: 2.5ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 16.1ms\n",
            "Speed: 2.1ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.5ms\n",
            "Speed: 2.5ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.9ms\n",
            "Speed: 4.6ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.8ms\n",
            "Speed: 5.1ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 10.1ms\n",
            "Speed: 2.2ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 10.3ms\n",
            "Speed: 18.8ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 14.0ms\n",
            "Speed: 2.2ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 11.7ms\n",
            "Speed: 2.2ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 10.1ms\n",
            "Speed: 2.4ms preprocess, 10.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 11.1ms\n",
            "Speed: 4.8ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 9.1ms\n",
            "Speed: 5.1ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 umbrella, 1 mouse, 1 scissors, 13.8ms\n",
            "Speed: 2.1ms preprocess, 13.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 8.9ms\n",
            "Speed: 3.0ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 umbrella, 1 mouse, 1 scissors, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.1ms\n",
            "Speed: 2.8ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.8ms\n",
            "Speed: 2.3ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.9ms\n",
            "Speed: 4.2ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 11.0ms\n",
            "Speed: 2.3ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 mouse, 1 scissors, 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.6ms\n",
            "Speed: 2.8ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.4ms\n",
            "Speed: 2.3ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.1ms\n",
            "Speed: 2.8ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.1ms\n",
            "Speed: 2.7ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.7ms\n",
            "Speed: 2.2ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.3ms\n",
            "Speed: 2.5ms preprocess, 12.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.9ms\n",
            "Speed: 2.4ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.3ms\n",
            "Speed: 3.1ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.0ms\n",
            "Speed: 3.4ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.9ms\n",
            "Speed: 2.5ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 15.7ms\n",
            "Speed: 1.9ms preprocess, 15.7ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.4ms\n",
            "Speed: 3.0ms preprocess, 13.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.5ms\n",
            "Speed: 3.0ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.5ms\n",
            "Speed: 2.4ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.8ms\n",
            "Speed: 2.1ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 11.7ms\n",
            "Speed: 4.0ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 9.7ms\n",
            "Speed: 2.5ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 9.9ms\n",
            "Speed: 2.2ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.7ms\n",
            "Speed: 2.5ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.7ms\n",
            "Speed: 2.2ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 banana, 1 scissors, 12.4ms\n",
            "Speed: 2.3ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 banana, 1 scissors, 9.4ms\n",
            "Speed: 2.3ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bananas, 1 scissors, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 banana, 1 scissors, 11.7ms\n",
            "Speed: 2.3ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 banana, 1 scissors, 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 banana, 1 scissors, 16.7ms\n",
            "Speed: 2.1ms preprocess, 16.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 banana, 1 scissors, 14.6ms\n",
            "Speed: 2.5ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 banana, 1 scissors, 11.0ms\n",
            "Speed: 2.3ms preprocess, 11.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 banana, 1 scissors, 9.9ms\n",
            "Speed: 2.4ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 banana, 1 scissors, 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 banana, 1 scissors, 9.8ms\n",
            "Speed: 2.1ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 banana, 1 scissors, 10.1ms\n",
            "Speed: 5.2ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 banana, 1 scissors, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 scissorss, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 8.6ms\n",
            "Speed: 5.0ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 10.9ms\n",
            "Speed: 2.2ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.4ms\n",
            "Speed: 2.7ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.1ms\n",
            "Speed: 2.1ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.4ms\n",
            "Speed: 3.0ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 banana, 1 scissors, 9.1ms\n",
            "Speed: 2.7ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 banana, 1 scissors, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 banana, 1 scissors, 9.1ms\n",
            "Speed: 3.9ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 banana, 1 scissors, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 banana, 1 scissors, 8.9ms\n",
            "Speed: 3.1ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 scissors, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 scissors, 9.8ms\n",
            "Speed: 2.5ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.8ms\n",
            "Speed: 2.1ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.2ms\n",
            "Speed: 3.4ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 16.0ms\n",
            "Speed: 2.3ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.2ms\n",
            "Speed: 2.4ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.9ms\n",
            "Speed: 2.2ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.8ms\n",
            "Speed: 2.1ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.0ms\n",
            "Speed: 3.6ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.9ms\n",
            "Speed: 2.2ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.0ms\n",
            "Speed: 2.6ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 12.5ms\n",
            "Speed: 3.7ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.2ms\n",
            "Speed: 2.3ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.7ms\n",
            "Speed: 2.2ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.9ms\n",
            "Speed: 2.2ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "[knife15_bright_kitchen_과도_none.mp4] 저장 완료: 50장\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 1 knife, 21.2ms\n",
            "Speed: 2.9ms preprocess, 21.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 1 knife, 15.2ms\n",
            "Speed: 2.3ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 1 banana, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 1 banana, 10.7ms\n",
            "Speed: 2.8ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 1 banana, 10.1ms\n",
            "Speed: 2.6ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 2 knifes, 1 banana, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 2 knifes, 1 banana, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 1 banana, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 2 knifes, 1 banana, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 2 knifes, 1 banana, 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 1 knife, 1 banana, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 1 knife, 1 banana, 10.3ms\n",
            "Speed: 2.2ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 1 knife, 1 banana, 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 1 knife, 1 banana, 9.8ms\n",
            "Speed: 3.3ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 2 knifes, 11.5ms\n",
            "Speed: 2.2ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 1 knife, 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 2 knifes, 1 oven, 9.6ms\n",
            "Speed: 3.5ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 2 knifes, 1 oven, 10.5ms\n",
            "Speed: 2.5ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 1 knife, 1 oven, 11.8ms\n",
            "Speed: 2.6ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 1 knife, 1 oven, 14.3ms\n",
            "Speed: 2.9ms preprocess, 14.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 1 knife, 1 oven, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 2 knifes, 1 oven, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 2 knifes, 1 oven, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 2 knifes, 1 oven, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 wine glass, 1 knife, 1 banana, 1 oven, 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 1 banana, 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 1 banana, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 1 oven, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 12.2ms\n",
            "Speed: 2.3ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 8.6ms\n",
            "Speed: 2.6ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 13.4ms\n",
            "Speed: 3.4ms preprocess, 13.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 wine glass, 1 knife, 8.3ms\n",
            "Speed: 2.0ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "[knife16_bright_floor_과도_yes.mp4] 저장 완료: 50장\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.9ms\n",
            "Speed: 3.9ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.9ms\n",
            "Speed: 2.9ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 12.0ms\n",
            "Speed: 2.2ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 23.1ms\n",
            "Speed: 3.0ms preprocess, 23.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.4ms\n",
            "Speed: 2.3ms preprocess, 13.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.9ms\n",
            "Speed: 2.9ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 15.8ms\n",
            "Speed: 2.2ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 14.0ms\n",
            "Speed: 4.9ms preprocess, 14.0ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 14.9ms\n",
            "Speed: 2.9ms preprocess, 14.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 13.4ms\n",
            "Speed: 2.2ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.8ms\n",
            "Speed: 2.3ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.6ms\n",
            "Speed: 2.9ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 14.9ms\n",
            "Speed: 2.2ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 12.2ms\n",
            "Speed: 1.7ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.7ms\n",
            "Speed: 8.2ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.5ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 15.0ms\n",
            "Speed: 2.3ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 5.0ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.8ms\n",
            "Speed: 2.9ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.5ms\n",
            "Speed: 2.3ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.1ms\n",
            "Speed: 4.2ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 17.6ms\n",
            "Speed: 2.4ms preprocess, 17.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 14.4ms\n",
            "Speed: 2.2ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 13.8ms\n",
            "Speed: 2.3ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 11.4ms\n",
            "Speed: 2.3ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 14.9ms\n",
            "Speed: 2.2ms preprocess, 14.9ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 14.2ms\n",
            "Speed: 2.1ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.8ms\n",
            "Speed: 3.2ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.6ms\n",
            "Speed: 2.5ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.0ms\n",
            "Speed: 2.1ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.2ms\n",
            "Speed: 3.5ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.2ms\n",
            "Speed: 1.7ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.4ms\n",
            "Speed: 2.3ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.7ms\n",
            "Speed: 2.2ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 10.8ms\n",
            "Speed: 2.5ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 1 scissors, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 1 scissors, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 1 scissors, 10.8ms\n",
            "Speed: 2.7ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 1 scissors, 15.3ms\n",
            "Speed: 2.7ms preprocess, 15.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 14.1ms\n",
            "Speed: 2.5ms preprocess, 14.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 1 scissors, 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 10.6ms\n",
            "Speed: 2.5ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 10.2ms\n",
            "Speed: 2.9ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 10.8ms\n",
            "Speed: 2.4ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 12.3ms\n",
            "Speed: 8.3ms preprocess, 12.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 1 scissors, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 1 scissors, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 1 scissors, 1 toothbrush, 18.0ms\n",
            "Speed: 2.5ms preprocess, 18.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 15.2ms\n",
            "Speed: 2.2ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 18.1ms\n",
            "Speed: 2.1ms preprocess, 18.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 1 scissors, 15.7ms\n",
            "Speed: 2.2ms preprocess, 15.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 14.7ms\n",
            "Speed: 2.3ms preprocess, 14.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 1 toothbrush, 14.7ms\n",
            "Speed: 2.3ms preprocess, 14.7ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 20.0ms\n",
            "Speed: 2.1ms preprocess, 20.0ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 1 scissors, 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 18.7ms\n",
            "Speed: 2.1ms preprocess, 18.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 25.2ms\n",
            "Speed: 2.2ms preprocess, 25.2ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 18.9ms\n",
            "Speed: 2.2ms preprocess, 18.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 11.2ms\n",
            "Speed: 4.2ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 19.2ms\n",
            "Speed: 5.5ms preprocess, 19.2ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.2ms\n",
            "Speed: 6.7ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.5ms\n",
            "Speed: 3.8ms preprocess, 10.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 15.5ms\n",
            "Speed: 2.1ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 12.3ms\n",
            "Speed: 2.9ms preprocess, 12.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 14.7ms\n",
            "Speed: 3.7ms preprocess, 14.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.4ms\n",
            "Speed: 3.4ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 14.5ms\n",
            "Speed: 2.3ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 14.2ms\n",
            "Speed: 2.4ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 11.1ms\n",
            "Speed: 2.8ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.9ms\n",
            "Speed: 2.8ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 11.9ms\n",
            "Speed: 2.2ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 knife, 1 scissors, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 15.5ms\n",
            "Speed: 2.4ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.8ms\n",
            "Speed: 2.8ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 20.6ms\n",
            "Speed: 2.0ms preprocess, 20.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.8ms\n",
            "Speed: 2.5ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 1 toothbrush, 10.8ms\n",
            "Speed: 3.2ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 1 toothbrush, 10.9ms\n",
            "Speed: 2.2ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 1 toothbrush, 14.4ms\n",
            "Speed: 2.3ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.8ms\n",
            "Speed: 2.6ms preprocess, 10.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 1 toothbrush, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 1 toothbrush, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 scissorss, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 scissorss, 10.8ms\n",
            "Speed: 4.2ms preprocess, 10.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 scissorss, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 12.8ms\n",
            "Speed: 3.4ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.7ms\n",
            "Speed: 2.1ms preprocess, 19.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 toothbrush, 16.2ms\n",
            "Speed: 2.1ms preprocess, 16.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 2.4ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.5ms\n",
            "Speed: 2.1ms preprocess, 20.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.9ms\n",
            "Speed: 2.0ms preprocess, 13.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.1ms\n",
            "Speed: 2.1ms preprocess, 14.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 scissorss, 13.5ms\n",
            "Speed: 2.3ms preprocess, 13.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 scissorss, 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 scissorss, 12.5ms\n",
            "Speed: 2.3ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 scissorss, 10.9ms\n",
            "Speed: 2.8ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 scissorss, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 scissorss, 16.8ms\n",
            "Speed: 2.0ms preprocess, 16.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 scissorss, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 scissorss, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 scissorss, 17.1ms\n",
            "Speed: 2.4ms preprocess, 17.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 10.9ms\n",
            "Speed: 6.4ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 14.0ms\n",
            "Speed: 2.4ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 11.0ms\n",
            "Speed: 2.4ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 12.8ms\n",
            "Speed: 2.4ms preprocess, 12.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 12.2ms\n",
            "Speed: 3.3ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 16.5ms\n",
            "Speed: 2.1ms preprocess, 16.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 11.3ms\n",
            "Speed: 2.4ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 scissorss, 10.9ms\n",
            "Speed: 2.2ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 scissorss, 11.3ms\n",
            "Speed: 2.4ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 scissorss, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 scissorss, 10.8ms\n",
            "Speed: 2.4ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 scissorss, 20.4ms\n",
            "Speed: 2.4ms preprocess, 20.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 21.7ms\n",
            "Speed: 2.3ms preprocess, 21.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 scissorss, 14.9ms\n",
            "Speed: 2.2ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 15.7ms\n",
            "Speed: 3.1ms preprocess, 15.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 scissorss, 16.7ms\n",
            "Speed: 2.3ms preprocess, 16.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 scissorss, 18.3ms\n",
            "Speed: 2.1ms preprocess, 18.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 16.3ms\n",
            "Speed: 4.7ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 toilet, 1 scissors, 13.4ms\n",
            "Speed: 4.4ms preprocess, 13.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 18.9ms\n",
            "Speed: 2.1ms preprocess, 18.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 21.3ms\n",
            "Speed: 2.3ms preprocess, 21.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 toilet, 1 scissors, 20.1ms\n",
            "Speed: 2.4ms preprocess, 20.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 toilet, 1 scissors, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 toilet, 1 scissors, 17.1ms\n",
            "Speed: 2.2ms preprocess, 17.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 toilet, 1 scissors, 15.2ms\n",
            "Speed: 4.3ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 toilet, 1 scissors, 14.7ms\n",
            "Speed: 2.1ms preprocess, 14.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 toilet, 1 scissors, 11.0ms\n",
            "Speed: 2.4ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 18.9ms\n",
            "Speed: 2.3ms preprocess, 18.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 11.4ms\n",
            "Speed: 2.7ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 15.8ms\n",
            "Speed: 2.7ms preprocess, 15.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 17.8ms\n",
            "Speed: 5.6ms preprocess, 17.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 18.8ms\n",
            "Speed: 2.6ms preprocess, 18.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.9ms\n",
            "Speed: 2.2ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.1ms\n",
            "Speed: 2.4ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 15.4ms\n",
            "Speed: 4.4ms preprocess, 15.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 18.0ms\n",
            "Speed: 2.1ms preprocess, 18.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 13.8ms\n",
            "Speed: 2.2ms preprocess, 13.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.8ms\n",
            "Speed: 5.6ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 12.4ms\n",
            "Speed: 4.6ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.9ms\n",
            "Speed: 7.3ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.8ms\n",
            "Speed: 2.1ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.0ms\n",
            "Speed: 2.3ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.3ms\n",
            "Speed: 2.2ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 13.1ms\n",
            "Speed: 2.1ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 scissorss, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.6ms\n",
            "Speed: 3.3ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 scissorss, 11.6ms\n",
            "Speed: 4.1ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 14.8ms\n",
            "Speed: 2.1ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.8ms\n",
            "Speed: 2.1ms preprocess, 14.8ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 3.2ms preprocess, 13.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.9ms\n",
            "Speed: 2.1ms preprocess, 20.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 2.5ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 4.0ms preprocess, 14.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 15.3ms\n",
            "Speed: 2.2ms preprocess, 15.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 toilet, 1 toothbrush, 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 toilet, 1 toothbrush, 16.2ms\n",
            "Speed: 6.2ms preprocess, 16.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 toilet, 1 toothbrush, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 toothbrush, 14.2ms\n",
            "Speed: 2.0ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 toothbrushs, 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 baseball bat, 1 toothbrush, 10.6ms\n",
            "Speed: 4.0ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 5.2ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 toothbrush, 17.6ms\n",
            "Speed: 2.2ms preprocess, 17.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.9ms\n",
            "Speed: 2.6ms preprocess, 13.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 toothbrush, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 toothbrush, 12.4ms\n",
            "Speed: 2.1ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 toothbrush, 14.7ms\n",
            "Speed: 5.2ms preprocess, 14.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.8ms\n",
            "Speed: 3.7ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 toothbrush, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 toothbrush, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 toothbrush, 15.1ms\n",
            "Speed: 6.1ms preprocess, 15.1ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 17.1ms\n",
            "Speed: 5.5ms preprocess, 17.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 scissors, 13.6ms\n",
            "Speed: 2.3ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 15.9ms\n",
            "Speed: 2.0ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 16.4ms\n",
            "Speed: 3.1ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 1 toothbrush, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 16.2ms\n",
            "Speed: 2.2ms preprocess, 16.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 13.5ms\n",
            "Speed: 2.0ms preprocess, 13.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 12.0ms\n",
            "Speed: 3.5ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 15.2ms\n",
            "Speed: 2.5ms preprocess, 15.2ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 15.5ms\n",
            "Speed: 2.1ms preprocess, 15.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.0ms\n",
            "Speed: 2.2ms preprocess, 12.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 15.4ms\n",
            "Speed: 4.5ms preprocess, 15.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 15.9ms\n",
            "Speed: 2.2ms preprocess, 15.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.8ms\n",
            "Speed: 3.0ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.2ms\n",
            "Speed: 2.9ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.7ms\n",
            "Speed: 2.2ms preprocess, 13.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.1ms\n",
            "Speed: 2.4ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.2ms\n",
            "Speed: 2.5ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.2ms\n",
            "Speed: 7.1ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.0ms\n",
            "Speed: 3.4ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 3.5ms preprocess, 10.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.7ms\n",
            "Speed: 2.4ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.0ms\n",
            "Speed: 2.3ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.5ms\n",
            "Speed: 2.2ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.9ms\n",
            "Speed: 3.4ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 19.5ms\n",
            "Speed: 2.5ms preprocess, 19.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.7ms\n",
            "Speed: 2.4ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 16.4ms\n",
            "Speed: 2.1ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 4.5ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.8ms\n",
            "Speed: 3.4ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 3.5ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.7ms\n",
            "Speed: 2.3ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.4ms\n",
            "Speed: 2.3ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 15.3ms\n",
            "Speed: 2.1ms preprocess, 15.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.7ms\n",
            "Speed: 2.4ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.4ms\n",
            "Speed: 2.3ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 scissorss, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 9.6ms\n",
            "Speed: 3.5ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 13.9ms\n",
            "Speed: 2.3ms preprocess, 13.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 15.8ms\n",
            "Speed: 2.3ms preprocess, 15.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 2 scissorss, 10.4ms\n",
            "Speed: 2.3ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.8ms\n",
            "Speed: 4.4ms preprocess, 14.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.3ms\n",
            "Speed: 2.7ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.2ms\n",
            "Speed: 2.1ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.6ms\n",
            "Speed: 3.1ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.7ms\n",
            "Speed: 4.4ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.7ms\n",
            "Speed: 3.4ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.8ms\n",
            "Speed: 3.3ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 12.1ms\n",
            "Speed: 2.5ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 13.0ms\n",
            "Speed: 2.6ms preprocess, 13.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 11.8ms\n",
            "Speed: 2.6ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 16.8ms\n",
            "Speed: 5.2ms preprocess, 16.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 15.0ms\n",
            "Speed: 3.7ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 17.2ms\n",
            "Speed: 2.7ms preprocess, 17.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.7ms\n",
            "Speed: 2.2ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "[knife17_bright_desk_식칼_yes.mp4] 저장 완료: 50장\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 13.5ms\n",
            "Speed: 3.9ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.5ms\n",
            "Speed: 2.5ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 15.6ms\n",
            "Speed: 2.3ms preprocess, 15.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 16.3ms\n",
            "Speed: 2.3ms preprocess, 16.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.4ms\n",
            "Speed: 2.3ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 16.3ms\n",
            "Speed: 1.7ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.7ms\n",
            "Speed: 2.2ms preprocess, 11.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.5ms\n",
            "Speed: 2.1ms preprocess, 14.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.0ms\n",
            "Speed: 2.2ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 15.1ms\n",
            "Speed: 2.1ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 4.0ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.1ms\n",
            "Speed: 2.1ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.7ms\n",
            "Speed: 2.4ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 21.9ms\n",
            "Speed: 2.2ms preprocess, 21.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.8ms\n",
            "Speed: 3.4ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.7ms\n",
            "Speed: 2.7ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.8ms\n",
            "Speed: 2.3ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.1ms\n",
            "Speed: 2.5ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.3ms\n",
            "Speed: 2.9ms preprocess, 10.3ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.9ms\n",
            "Speed: 2.2ms preprocess, 13.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.8ms\n",
            "Speed: 3.5ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 13.2ms\n",
            "Speed: 2.1ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.6ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 2.4ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 3.6ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 2.2ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 2.4ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 5.9ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 2.5ms preprocess, 11.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 2.2ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 2.1ms preprocess, 13.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.2ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 3.0ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 2.4ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 2.9ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.2ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 2.2ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 4.2ms preprocess, 15.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 3.9ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 2.1ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.0ms preprocess, 13.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 2.4ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.9ms\n",
            "Speed: 2.4ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 3.0ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.7ms\n",
            "Speed: 3.6ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 2.4ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.7ms\n",
            "Speed: 2.2ms preprocess, 9.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.2ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 3.8ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.7ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 2.6ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 8.2ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.4ms\n",
            "Speed: 2.3ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 5.1ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 2.3ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 2.3ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 3.5ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 5.3ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.5ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 2.1ms preprocess, 16.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 2.3ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 3.1ms preprocess, 9.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.1ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.2ms\n",
            "Speed: 3.2ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 2.1ms preprocess, 12.7ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 2.0ms preprocess, 16.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 2.6ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.5ms\n",
            "Speed: 2.3ms preprocess, 17.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 4.1ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 refrigerator, 15.4ms\n",
            "Speed: 2.0ms preprocess, 15.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.1ms\n",
            "Speed: 2.2ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 2.4ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 4.6ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.4ms\n",
            "Speed: 2.2ms preprocess, 21.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.4ms\n",
            "Speed: 2.1ms preprocess, 19.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 2.4ms preprocess, 9.6ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 5.4ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 3.5ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.9ms\n",
            "Speed: 3.1ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.1ms\n",
            "Speed: 2.3ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 2.0ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 2.1ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.8ms\n",
            "Speed: 3.1ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.8ms\n",
            "Speed: 2.1ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.2ms\n",
            "Speed: 2.3ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 17.8ms\n",
            "Speed: 5.3ms preprocess, 17.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.3ms\n",
            "Speed: 2.4ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.3ms\n",
            "Speed: 4.9ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.0ms\n",
            "Speed: 2.8ms preprocess, 14.0ms inference, 9.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.5ms\n",
            "Speed: 2.5ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 13.0ms\n",
            "Speed: 2.5ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 10.3ms\n",
            "Speed: 2.4ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 18.8ms\n",
            "Speed: 2.2ms preprocess, 18.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 11.8ms\n",
            "Speed: 9.2ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 12.4ms\n",
            "Speed: 2.3ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 10.3ms\n",
            "Speed: 3.6ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 10.2ms\n",
            "Speed: 2.4ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.7ms\n",
            "Speed: 2.6ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 14.5ms\n",
            "Speed: 2.3ms preprocess, 14.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 11.0ms\n",
            "Speed: 6.1ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.2ms\n",
            "Speed: 2.6ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 12.4ms\n",
            "Speed: 2.5ms preprocess, 12.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 13.7ms\n",
            "Speed: 2.7ms preprocess, 13.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 13.7ms\n",
            "Speed: 2.4ms preprocess, 13.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.2ms\n",
            "Speed: 2.6ms preprocess, 12.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.9ms\n",
            "Speed: 2.5ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.4ms\n",
            "Speed: 2.4ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 11.0ms\n",
            "Speed: 2.3ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 2.5ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 10.4ms\n",
            "Speed: 2.4ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 9.6ms\n",
            "Speed: 3.8ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 11.0ms\n",
            "Speed: 2.3ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 9.7ms\n",
            "Speed: 2.2ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.9ms\n",
            "Speed: 2.2ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.6ms\n",
            "Speed: 1.7ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 15.5ms\n",
            "Speed: 2.2ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.5ms\n",
            "Speed: 2.4ms preprocess, 14.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 15.8ms\n",
            "Speed: 2.6ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.3ms\n",
            "Speed: 2.1ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.6ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.5ms\n",
            "Speed: 2.2ms preprocess, 20.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.4ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 16.6ms\n",
            "Speed: 2.1ms preprocess, 16.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 15.0ms\n",
            "Speed: 2.2ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 4.6ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 18.2ms\n",
            "Speed: 2.4ms preprocess, 18.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 16.1ms\n",
            "Speed: 2.3ms preprocess, 16.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.0ms\n",
            "Speed: 2.2ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 16.4ms\n",
            "Speed: 4.2ms preprocess, 16.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 2.6ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 20.1ms\n",
            "Speed: 2.0ms preprocess, 20.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.1ms\n",
            "Speed: 5.2ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.3ms\n",
            "Speed: 4.3ms preprocess, 14.3ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 3.0ms preprocess, 14.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 4.1ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 4.0ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.4ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.4ms\n",
            "Speed: 2.3ms preprocess, 17.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.2ms\n",
            "Speed: 2.2ms preprocess, 13.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 1.7ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 4.7ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 4.1ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 2.4ms preprocess, 16.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 4.0ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 2.6ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 13.5ms\n",
            "Speed: 3.1ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 toothbrushs, 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 9.6ms\n",
            "Speed: 3.2ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.2ms preprocess, 13.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 toothbrushs, 15.2ms\n",
            "Speed: 2.3ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.4ms\n",
            "Speed: 2.2ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.8ms\n",
            "Speed: 2.3ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.1ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 4.9ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 3.5ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.7ms\n",
            "Speed: 2.1ms preprocess, 16.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 2.0ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.1ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 4.9ms preprocess, 12.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.2ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 5.9ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.2ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.4ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.1ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 5.0ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 2.4ms preprocess, 12.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.0ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.2ms preprocess, 14.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.7ms\n",
            "Speed: 2.1ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.7ms\n",
            "Speed: 3.9ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 2.1ms preprocess, 14.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.1ms preprocess, 14.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 2.2ms preprocess, 13.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 14.5ms\n",
            "Speed: 2.0ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 13.1ms\n",
            "Speed: 2.1ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 16.2ms\n",
            "Speed: 2.3ms preprocess, 16.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 15.7ms\n",
            "Speed: 2.3ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 scissors, 13.2ms\n",
            "Speed: 4.1ms preprocess, 13.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.9ms\n",
            "Speed: 2.2ms preprocess, 13.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.5ms\n",
            "Speed: 3.5ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.8ms\n",
            "Speed: 3.3ms preprocess, 10.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.9ms\n",
            "Speed: 3.3ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 17.9ms\n",
            "Speed: 2.2ms preprocess, 17.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.3ms\n",
            "Speed: 4.9ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.9ms\n",
            "Speed: 2.1ms preprocess, 14.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.0ms\n",
            "Speed: 2.2ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 16.3ms\n",
            "Speed: 2.1ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.5ms\n",
            "Speed: 2.1ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.7ms\n",
            "Speed: 2.5ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.9ms\n",
            "Speed: 6.4ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 14.9ms\n",
            "Speed: 4.4ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.9ms\n",
            "Speed: 2.2ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 15.1ms\n",
            "Speed: 2.2ms preprocess, 15.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 13.3ms\n",
            "Speed: 2.0ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 12.0ms\n",
            "Speed: 3.2ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.8ms\n",
            "Speed: 2.1ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.1ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 3.5ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 16.5ms\n",
            "Speed: 2.2ms preprocess, 16.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.2ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 5.7ms preprocess, 15.0ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.4ms\n",
            "Speed: 2.4ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 16.9ms\n",
            "Speed: 2.2ms preprocess, 16.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 16.6ms\n",
            "Speed: 2.5ms preprocess, 16.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.5ms\n",
            "Speed: 3.2ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 16.3ms\n",
            "Speed: 1.9ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 9.8ms\n",
            "Speed: 2.1ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 17.7ms\n",
            "Speed: 4.0ms preprocess, 17.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 9.9ms\n",
            "Speed: 4.5ms preprocess, 9.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 11.8ms\n",
            "Speed: 2.3ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 12.3ms\n",
            "Speed: 3.9ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 1 toothbrush, 9.8ms\n",
            "Speed: 2.1ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 13.7ms\n",
            "Speed: 4.5ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 15.6ms\n",
            "Speed: 2.2ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.1ms\n",
            "Speed: 2.1ms preprocess, 19.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 18.7ms\n",
            "Speed: 2.2ms preprocess, 18.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.2ms preprocess, 17.1ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 15.3ms\n",
            "Speed: 2.4ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 18.7ms\n",
            "Speed: 2.4ms preprocess, 18.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 12.1ms\n",
            "Speed: 2.2ms preprocess, 12.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 19.2ms\n",
            "Speed: 2.2ms preprocess, 19.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 16.4ms\n",
            "Speed: 2.2ms preprocess, 16.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 18.6ms\n",
            "Speed: 2.2ms preprocess, 18.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 20.7ms\n",
            "Speed: 2.5ms preprocess, 20.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 13.3ms\n",
            "Speed: 2.2ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.5ms\n",
            "Speed: 2.5ms preprocess, 21.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 17.3ms\n",
            "Speed: 3.3ms preprocess, 17.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 13.7ms\n",
            "Speed: 2.2ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.1ms\n",
            "Speed: 2.5ms preprocess, 18.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 3.3ms preprocess, 16.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.3ms\n",
            "Speed: 2.2ms preprocess, 21.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 3.4ms preprocess, 15.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 12.6ms\n",
            "Speed: 2.3ms preprocess, 12.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 2.2ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.2ms\n",
            "Speed: 2.1ms preprocess, 18.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.1ms preprocess, 14.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.6ms\n",
            "Speed: 2.4ms preprocess, 18.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.2ms\n",
            "Speed: 2.2ms preprocess, 17.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 16.5ms\n",
            "Speed: 2.2ms preprocess, 16.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.7ms\n",
            "Speed: 4.6ms preprocess, 16.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.8ms\n",
            "Speed: 2.2ms preprocess, 17.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.2ms\n",
            "Speed: 2.3ms preprocess, 19.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.9ms\n",
            "Speed: 2.2ms preprocess, 18.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.5ms\n",
            "Speed: 3.9ms preprocess, 18.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.7ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 3.2ms preprocess, 12.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.2ms preprocess, 14.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.8ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.4ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 4.2ms preprocess, 12.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 4.4ms preprocess, 17.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.3ms preprocess, 16.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 2.5ms preprocess, 13.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.0ms\n",
            "Speed: 2.2ms preprocess, 20.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 17.1ms\n",
            "Speed: 2.2ms preprocess, 17.1ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 11.9ms\n",
            "Speed: 2.3ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 11.1ms\n",
            "Speed: 3.0ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 11.4ms\n",
            "Speed: 2.3ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 16.6ms\n",
            "Speed: 2.4ms preprocess, 16.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 18.9ms\n",
            "Speed: 2.3ms preprocess, 18.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 15.9ms\n",
            "Speed: 2.4ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 11.8ms\n",
            "Speed: 3.4ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 16.7ms\n",
            "Speed: 4.4ms preprocess, 16.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 12.5ms\n",
            "Speed: 2.7ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 12.0ms\n",
            "Speed: 2.5ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 12.2ms\n",
            "Speed: 2.2ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 11.4ms\n",
            "Speed: 2.3ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 16.1ms\n",
            "Speed: 3.6ms preprocess, 16.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.5ms preprocess, 10.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 2.5ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.8ms\n",
            "Speed: 2.4ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.3ms\n",
            "Speed: 2.8ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.3ms\n",
            "Speed: 3.2ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 11.9ms\n",
            "Speed: 3.2ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 10.2ms\n",
            "Speed: 3.4ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "[knife18_bright_window_커터칼_yes.mp4] 저장 완료: 0장\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 17.1ms\n",
            "Speed: 2.1ms preprocess, 17.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 19.3ms\n",
            "Speed: 2.3ms preprocess, 19.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 14.9ms\n",
            "Speed: 2.3ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 10.4ms\n",
            "Speed: 2.7ms preprocess, 10.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 11.1ms\n",
            "Speed: 2.4ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 10.2ms\n",
            "Speed: 3.1ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 10.2ms\n",
            "Speed: 2.9ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 10.2ms\n",
            "Speed: 3.1ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 12.3ms\n",
            "Speed: 2.9ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 11.8ms\n",
            "Speed: 2.5ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 13.2ms\n",
            "Speed: 1.7ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 10.8ms\n",
            "Speed: 3.2ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 10.3ms\n",
            "Speed: 4.1ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 1 scissors, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 1 scissors, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 1 scissors, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 1 scissors, 10.6ms\n",
            "Speed: 6.0ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 1 scissors, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 1 scissors, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 1 scissors, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 1 scissors, 12.9ms\n",
            "Speed: 2.2ms preprocess, 12.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 1 scissors, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 1 scissors, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 1 scissors, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 1 scissors, 14.0ms\n",
            "Speed: 3.4ms preprocess, 14.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 1 scissors, 15.5ms\n",
            "Speed: 6.3ms preprocess, 15.5ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 1 scissors, 16.8ms\n",
            "Speed: 2.1ms preprocess, 16.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 1 scissors, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 1 scissors, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 14.8ms\n",
            "Speed: 2.2ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 10.4ms\n",
            "Speed: 2.4ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 15.3ms\n",
            "Speed: 3.4ms preprocess, 15.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 15.3ms\n",
            "Speed: 2.6ms preprocess, 15.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 14.0ms\n",
            "Speed: 2.2ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 11.2ms\n",
            "Speed: 2.4ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 scissors, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 1 scissors, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 3.1ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 2.7ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.4ms preprocess, 14.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 laptop, 2 scissorss, 20.6ms\n",
            "Speed: 2.2ms preprocess, 20.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 laptop, 2 scissorss, 14.9ms\n",
            "Speed: 2.3ms preprocess, 14.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cat, 2 scissorss, 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cat, 2 scissorss, 17.4ms\n",
            "Speed: 2.3ms preprocess, 17.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cat, 2 scissorss, 18.8ms\n",
            "Speed: 2.1ms preprocess, 18.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cat, 2 scissorss, 16.4ms\n",
            "Speed: 2.2ms preprocess, 16.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cat, 1 scissors, 14.2ms\n",
            "Speed: 2.3ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cat, 1 scissors, 16.6ms\n",
            "Speed: 1.7ms preprocess, 16.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cat, 2 scissorss, 10.8ms\n",
            "Speed: 2.8ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cat, 1 scissors, 11.2ms\n",
            "Speed: 1.7ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cat, 1 scissors, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cat, 1 scissors, 19.6ms\n",
            "Speed: 2.0ms preprocess, 19.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cat, 1 scissors, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cat, 2 scissorss, 10.8ms\n",
            "Speed: 2.4ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bed, 2 scissorss, 14.9ms\n",
            "Speed: 2.0ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cat, 1 bed, 2 scissorss, 10.8ms\n",
            "Speed: 3.7ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cat, 2 scissorss, 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cat, 2 scissorss, 11.5ms\n",
            "Speed: 2.3ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cat, 2 scissorss, 10.8ms\n",
            "Speed: 3.6ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cat, 2 scissorss, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cat, 2 scissorss, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cat, 2 scissorss, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cat, 2 scissorss, 10.8ms\n",
            "Speed: 2.3ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cat, 2 scissorss, 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cat, 2 scissorss, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 scissorss, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 2 scissorss, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 2 scissorss, 12.8ms\n",
            "Speed: 3.4ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 2 scissorss, 10.9ms\n",
            "Speed: 4.0ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 2 scissorss, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 2 scissorss, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 2 scissorss, 13.5ms\n",
            "Speed: 2.2ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 2 scissorss, 10.9ms\n",
            "Speed: 4.2ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 2 scissorss, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 2 scissorss, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 2 scissorss, 16.2ms\n",
            "Speed: 3.5ms preprocess, 16.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 2 scissorss, 10.9ms\n",
            "Speed: 5.3ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 2 scissorss, 13.8ms\n",
            "Speed: 5.4ms preprocess, 13.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 21.0ms\n",
            "Speed: 2.3ms preprocess, 21.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cat, 1 scissors, 15.9ms\n",
            "Speed: 2.4ms preprocess, 15.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cat, 1 bed, 1 scissors, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 1 scissors, 10.9ms\n",
            "Speed: 5.7ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 1 scissors, 19.4ms\n",
            "Speed: 2.2ms preprocess, 19.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 2 scissorss, 13.6ms\n",
            "Speed: 2.4ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 1 scissors, 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 1 scissors, 14.9ms\n",
            "Speed: 2.2ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 scissors, 10.8ms\n",
            "Speed: 3.1ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 2 scissorss, 11.7ms\n",
            "Speed: 2.2ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 scissorss, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 2 scissorss, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 1 scissors, 13.1ms\n",
            "Speed: 2.1ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 1 scissors, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 2 scissorss, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 1 scissors, 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 10.6ms\n",
            "Speed: 3.4ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 11.2ms\n",
            "Speed: 2.3ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 14.7ms\n",
            "Speed: 2.0ms preprocess, 14.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 13.4ms\n",
            "Speed: 2.3ms preprocess, 13.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 knife, 1 bed, 16.8ms\n",
            "Speed: 3.2ms preprocess, 16.8ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "[knife19_dark_livingroom_식칼_none.mp4] 저장 완료: 50장\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "iz32GyvmYg0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (4) 본인이 생성한 데이터 평가\n",
        "\n",
        "본 프로젝트에서 사용한 데이터는 본인이 직접 생성한 이미지 데이터이다.  \n",
        "총 19개의 조건 조합(조도, 배경, 칼 종류, 오클루전 포함)에 따라 영상을 촬영하였고,  \n",
        "YOLOv8 객체 탐지 모델을 활용하여 각 영상으로부터 칼 객체만을 crop하여 이미지로 저장하였다.\n",
        "\n",
        "| 번호 | 조도  | 배경 | 오클루전 | 칼 종류 | 파일명                                       |\n",
        "| -- | --- | -- | ---- | ---- | ----------------------------------------- |\n",
        "| 1  | 밝음  | 주방 | 없음   | 식칼   | knife01\\_bright\\_kitchen\\_식칼\\_none.mp4    |\n",
        "| 2  | 어두움 | 책상 | 없음   | 과도   | knife02\\_dark\\_desk\\_과도\\_none.mp4         |\n",
        "| 3  | 밝음  | 거실 | 있음   | 커터칼  | knife03\\_bright\\_livingroom\\_커터칼\\_yes.mp4 |\n",
        "| 4  | 밝음  | 바닥 | 없음   | 식칼   | knife04\\_bright\\_floor\\_식칼\\_none.mp4      |\n",
        "| 5  | 어두움 | 주방 | 있음   | 과도   | knife05\\_dark\\_kitchen\\_과도\\_yes.mp4       |\n",
        "| 6  | 밝음  | 창가 | 없음   | 커터칼  | knife06\\_bright\\_window\\_커터칼\\_none.mp4    |\n",
        "| 7  | 밝음  | 책상 | 있음   | 식칼   | knife07\\_bright\\_desk\\_식칼\\_yes.mp4        |\n",
        "| 8  | 어두움 | 거실 | 없음   | 커터칼  | knife08\\_dark\\_livingroom\\_커터칼\\_none.mp4  |\n",
        "| 9  | 어두움 | 바닥 | 있음   | 커터칼  | knife09\\_dark\\_floor\\_커터칼\\_yes.mp4        |\n",
        "| 10 | 어두움 | 창가 | 있음   | 커터칼  | knife10\\_dark\\_window\\_커터칼\\_yes.mp4       |\n",
        "| 11 | 밝음  | 바닥 | 있음   | 커터칼  | knife11\\_bright\\_floor\\_커터칼\\_yes.mp4      |\n",
        "| 12 | 어두움 | 주방 | 없음   | 커터칼  | knife12\\_dark\\_kitchen\\_커터칼\\_none.mp4     |\n",
        "| 13 | 밝음  | 창가 | 있음   | 커터칼  | knife13\\_bright\\_window\\_커터칼\\_yes.mp4     |\n",
        "| 14 | 어두움 | 바닥 | 있음   | 과도   | knife14\\_dark\\_floor\\_과도\\_yes.mp4         |\n",
        "| 15 | 밝음  | 주방 | 없음   | 과도   | knife15\\_bright\\_kitchen\\_과도\\_none.mp4    |\n",
        "| 16 | 밝음  | 바닥 | 있음   | 과도   | knife16\\_bright\\_floor\\_과도\\_yes.mp4       |\n",
        "| 17 | 밝음  | 책상 | 있음   | 식칼   | knife17\\_bright\\_desk\\_식칼\\_yes.mp4        |\n",
        "| 18 | 밝음  | 창가 | 있음   | 커터칼  | knife18\\_bright\\_window\\_커터칼\\_yes.mp4     |\n",
        "| 19 | 어두움 | 거실 | 없음   | 식칼   | knife19\\_dark\\_livingroom\\_식칼\\_none.mp4   |\n",
        "\n",
        "\n",
        "[Note 3] 생성한 데이터셋은 이주원의 Github (https://github.com/jwdebbie/knife-classification) 에 업로드되어 있으며, 해당 데이터 링크를 프로그램에서 불러 딥러닝 프로그래밍을 진행한다.\n",
        "\n",
        "[Note 4] 데이터는 집에서 어머니와 함께 직접 촬영한 영상데이터를 활용하였다. 데이터 편향 극복을 위해 8개의 영상에서 총 19개의 영상으로 그 수를 늘려서 균형을 확보하였다.\n",
        "\n",
        "[Note 5] 본 프로젝트의 데이터는 동영상에서 추출한 이미지 프레임으로 구성된 이미지 데이터이며, 다양한 조건(조도, 배경, 오클루전 등)에 따른 패턴 인식이 가능하도록 설계되었다."
      ],
      "metadata": {
        "id": "9d1FhrCqa1OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성된 데이터셋 .zip으로 압축하기 (github 올리기용)\n",
        "\n",
        "!zip -r knives_dataset.zip knives_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkbPsB2JWm4X",
        "outputId": "682ffc9a-72ec-4510-cd9e-4fb7c5f542c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: knives_dataset/ (stored 0%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/ (stored 0%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0035.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0056.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0005.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0030.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0011.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0033.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0040.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0043.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0048.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0019.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0002.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0009.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0065.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0006.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0024.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0004.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0016.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0027.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0044.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0059.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0012.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0026.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0022.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0028.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0003.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0034.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0055.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0013.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0039.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0008.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0001.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0018.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0069.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0020.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0029.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0025.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0031.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0038.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0014.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0054.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0032.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0017.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0036.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0007.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0000.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0010.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0046.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0023.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0021.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife02_dark_desk_과도_none/knife_0041.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife07_bright_desk_식칼_yes/ (stored 0%)\n",
            "  adding: knives_dataset/knife07_bright_desk_식칼_yes/knife_0019.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife07_bright_desk_식칼_yes/knife_0022.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife07_bright_desk_식칼_yes/knife_0023.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife07_bright_desk_식칼_yes/knife_0021.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/ (stored 0%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0324.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0370.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0343.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0359.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0332.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0345.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0333.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0344.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0418.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0342.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0334.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0417.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0368.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0351.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0335.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0331.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0336.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0330.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0415.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0369.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0416.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0350.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0323.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife03_bright_livingroom_커터칼_yes/knife_0414.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/ (stored 0%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0072.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0056.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0005.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0131.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0033.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0129.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0090.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0343.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0130.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0339.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0117.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0332.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0124.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0002.jpg (deflated 5%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0333.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0121.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0110.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0109.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0334.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0004.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0125.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0059.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0122.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0335.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0331.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0003.jpg (deflated 5%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0134.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0055.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0330.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0039.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0337.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0150.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0001.jpg (deflated 6%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0051.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0037.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0038.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0042.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0120.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0054.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0133.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0032.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0119.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0127.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0089.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0050.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0132.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0126.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0123.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0000.jpg (deflated 6%)\n",
            "  adding: knives_dataset/knife15_bright_kitchen_과도_none/knife_0128.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/ (stored 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0035.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0056.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0005.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0011.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0131.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0129.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0130.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0052.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0124.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0048.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0002.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0009.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0121.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0006.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0137.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0004.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0015.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0125.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0118.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0122.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0012.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0003.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0134.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0034.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0055.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0013.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0138.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0136.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0008.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0001.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0051.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0037.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0053.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0038.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0014.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0135.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0054.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0133.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0017.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0119.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0036.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0007.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0127.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0050.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0139.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0132.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0126.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0123.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0000.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife19_dark_livingroom_식칼_none/knife_0128.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/ (stored 0%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0853.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0660.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0688.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0715.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0691.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0541.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0523.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0694.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0686.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0665.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0662.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0714.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0143.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0539.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0481.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0543.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0675.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0689.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0684.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0856.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0716.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0680.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0525.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0855.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0854.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0538.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0674.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0717.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0658.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0216.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0480.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0661.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0663.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0113.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0687.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0693.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0685.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0672.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0659.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0736.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0649.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0679.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0673.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0540.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0544.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0146.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0677.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0153.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0664.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife13_bright_window_커터칼_yes/knife_0690.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife12_dark_kitchen_커터칼_none/ (stored 0%)\n",
            "  adding: knives_dataset/knife12_dark_kitchen_커터칼_none/knife_0485.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife12_dark_kitchen_커터칼_none/knife_0093.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife10_dark_window_커터칼_yes/ (stored 0%)\n",
            "  adding: knives_dataset/knife10_dark_window_커터칼_yes/knife_0315.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife10_dark_window_커터칼_yes/knife_0156.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife10_dark_window_커터칼_yes/knife_0157.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife10_dark_window_커터칼_yes/knife_0065.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife10_dark_window_커터칼_yes/knife_0199.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife10_dark_window_커터칼_yes/knife_0299.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife10_dark_window_커터칼_yes/knife_0300.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/ (stored 0%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0035.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0005.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0030.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0011.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0033.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0019.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0002.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0009.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0006.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0024.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0004.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0016.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0027.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0015.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0012.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0026.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0022.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0028.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0003.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0034.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0013.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0039.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0008.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0001.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0018.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0037.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0020.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0029.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0025.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0031.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0038.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0014.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0032.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0017.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0036.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0007.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0000.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0010.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0023.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife16_bright_floor_과도_yes/knife_0021.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/ (stored 0%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0145.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0005.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0011.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0131.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0129.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0130.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0148.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0019.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0002.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0009.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0147.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0143.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0142.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0006.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0154.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0004.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0016.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0015.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0152.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0012.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0022.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0003.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0140.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0134.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0013.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0136.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0150.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0008.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0001.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0141.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0018.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0149.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0020.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0155.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0014.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0144.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0135.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0151.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0133.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0017.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0007.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0127.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0132.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0126.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0000.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0010.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0146.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0153.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0021.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife05_dark_kitchen_과도_yes/knife_0128.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/ (stored 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0276.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0082.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0355.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0364.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0086.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0090.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0359.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0277.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0280.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0345.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0344.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0362.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0346.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0349.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0368.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0279.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0079.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0278.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0341.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0351.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0081.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0083.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0336.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0363.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0367.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0285.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0337.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0100.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0354.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0353.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0093.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0088.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0350.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0096.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0356.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0348.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0089.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0087.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0080.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0092.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0357.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0361.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0085.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0360.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0091.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0352.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0358.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0077.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0347.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife17_bright_desk_식칼_yes/knife_0128.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife08_dark_livingroom_커터칼_none/ (stored 0%)\n",
            "  adding: knives_dataset/knife08_dark_livingroom_커터칼_none/knife_0090.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife08_dark_livingroom_커터칼_none/knife_0158.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife08_dark_livingroom_커터칼_none/knife_0154.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife08_dark_livingroom_커터칼_none/knife_0088.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife08_dark_livingroom_커터칼_none/knife_1078.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife08_dark_livingroom_커터칼_none/knife_0089.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife08_dark_livingroom_커터칼_none/knife_0087.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife08_dark_livingroom_커터칼_none/knife_0085.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife08_dark_livingroom_커터칼_none/knife_0146.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife08_dark_livingroom_커터칼_none/knife_0091.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife08_dark_livingroom_커터칼_none/knife_0153.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife06_bright_window_커터칼_none/ (stored 0%)\n",
            "  adding: knives_dataset/knife06_bright_window_커터칼_none/knife_0086.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife06_bright_window_커터칼_none/knife_0090.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife06_bright_window_커터칼_none/knife_0088.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife06_bright_window_커터칼_none/knife_0089.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife06_bright_window_커터칼_none/knife_0087.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife06_bright_window_커터칼_none/knife_0080.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife06_bright_window_커터칼_none/knife_0092.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife06_bright_window_커터칼_none/knife_0091.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/ (stored 0%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0676.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0198.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0691.jpg (deflated 6%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0098.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0102.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0117.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0097.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0095.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0124.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0148.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0290.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0143.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0121.jpg (deflated 5%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0142.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0678.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0111.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0110.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0105.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0154.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0109.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0116.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0675.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0125.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0118.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0122.jpg (deflated 5%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0140.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0674.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0138.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0093.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0094.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0103.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0114.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0141.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0108.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0149.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0096.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0107.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0155.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0120.jpg (deflated 6%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0144.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0135.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0151.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0106.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0119.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0139.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0092.jpg (deflated 5%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0104.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0291.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0126.jpg (deflated 4%)\n",
            "  adding: knives_dataset/knife09_dark_floor_커터칼_yes/knife_0091.jpg (deflated 5%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/ (stored 0%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0072.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0084.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0082.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0040.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0086.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0090.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0162.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0163.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0095.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0156.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0157.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0019.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0002.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0079.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0044.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0160.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0081.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0083.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0028.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0070.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0055.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0164.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0093.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0094.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0088.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0165.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0020.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0029.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0078.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0161.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0074.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0127.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0089.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0087.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0080.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0071.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0092.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0061.jpg (deflated 0%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0085.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0091.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0153.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife04_bright_floor_식칼_none/knife_0128.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/ (stored 0%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0035.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0005.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0030.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0011.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0033.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0040.jpg (deflated 7%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0019.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0002.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0009.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0006.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0024.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0004.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0016.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0027.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0015.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0012.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0026.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0022.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0028.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0003.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0034.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0013.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0039.jpg (deflated 7%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0008.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0001.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0018.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0037.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0020.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0029.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0025.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0031.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0038.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0014.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0032.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0017.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0036.jpg (deflated 7%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0007.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0000.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0010.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0023.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife01_bright_kitchen_식칼_none/knife_0021.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife18_bright_window_커터칼_yes/ (stored 0%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/ (stored 0%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0035.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0005.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0030.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0011.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0033.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0040.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0043.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0048.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0019.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0002.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0009.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0047.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0006.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0024.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0004.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0016.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0027.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0015.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0044.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0012.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0026.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0022.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0045.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0028.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0003.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0049.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0034.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0013.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0039.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0008.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0001.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0018.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0037.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0020.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0029.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0025.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0031.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0038.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0042.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0014.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0032.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0017.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0036.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0007.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0000.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0010.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0046.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0023.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0021.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife14_dark_floor_과도_yes/knife_0041.jpg (deflated 2%)\n",
            "  adding: knives_dataset/knife11_bright_floor_커터칼_yes/ (stored 0%)\n",
            "  adding: knives_dataset/knife11_bright_floor_커터칼_yes/knife_0321.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife11_bright_floor_커터칼_yes/knife_0142.jpg (deflated 3%)\n",
            "  adding: knives_dataset/knife11_bright_floor_커터칼_yes/knife_0322.jpg (deflated 1%)\n",
            "  adding: knives_dataset/knife11_bright_floor_커터칼_yes/knife_0141.jpg (deflated 3%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "mRBlJg2dYvwV"
      }
    }
  ]
}